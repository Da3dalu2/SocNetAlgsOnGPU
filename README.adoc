= Social Network Analysis Algorithms on GPU

ifdef::env-github[]
:note-caption: :information_source:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]

A command-line GPU-accelerated application for computing Betweenness Centrality of sparse graphs that represent social networks.

== Installation

=== Prerequisites

These are the dependencies needed to build the project:

- GCC must be installed;
- link:https://developer.nvidia.com/cuda-downloads[CUDA Toolkit 11+] must be installed;
- link:https://cmake.org/download/[CMake 3.9+] to build the project;
- The link:https://www.boost.org/users/history/version_1_75_0.html[Parallel Boost Graph Library] is used for the CPU reference implementation of the Betweenness Centrality algorithm;
- link:

There also some optional dependencies:

- To launch the benchmarks with the script given, link:script/perf_eval.sh[perf-eval,sh], a Unix Shell must be available;
- link:https://www.python.org/downloads/[Python 3] to execute the script that
processes the result of the benchmarking;
- link:https://www.ruby-lang.org/en/downloads/[Ruby] and some gems listed in the link:{docdir}/script/Gemfile[Gemfile] to generate the report;
- `clang-format` for formatting the source code and `clang-tidy` for static code analysis;

[WARNING]
====
During the development of the project only GCC 10.3.0 on Ubuntu 18.04 has been tested.
====

=== Compilation

First clone this repo and enter it:

[source,shell]
----
git clone https://github.com/Da3dalu2/SocNetAlgsOnGPU.git
cd SocNetAlgsOnGPU
----

To build this project with CMake:

[source,shell]
----
mkdir build-release && cd build-release
cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_CUDA_ARCHITECTURES=60
----

Binary source file are available in `build/src` directory.

Binary test files are available in `build/test` directory. All tests can be run by typing `ctest` in the `build/test` directory.

[TIP]
====
To run all tests in parallel just issue the `ctest -j4` in the `build/test` directory.
====

Detailed test log from `ctest` can be found in `/build/Testing/Temporary/LastTest.log`, alternatively tests can be run with the verbose option enabled, i.e. `ctest -v`.

[NOTE]
====
There are two build types available, Release and Debug. Release builds
with optimization flags enabled (`-O2`) and Debug uses both debug symbols (`-g`) for ease of use of GBD and Valgrind and `-Wall -Werror -Wpedantic`.
====

=== Generating Datasets

All dataset-related code is under the `dataset` subdirectory. Only link:https://math.nist.gov/MatrixMarket/formats.html[Matrix-market] coordinate-formatted graph format is supported.

A script for generating random graphs is given, `dataset/graph_gen`.

Currently, only undirected and unweighted graphs are supported.

To download them just type `make` in the `dataset` subdirectory. To only download one specific dataset step into its subdirectory and type `make` there.

=== Libraries

Included in the project there are the SNAP library from the link:https://snap.stanford.edu/snap/index.html[SNAP System], used for random graph generation from the link:https://snap.stanford.edu/data/index.html[Stanford Large Network Dataset Collection].

In addition there is the link:https://math.nist.gov/MatrixMarket/mmio-c.html[library for parsing Matrix Market files].

Finally, the link:https://github.com/onqtam/doctest[doctest] header file for testing {cpp} code and the link:https://github.com/wonder-mice/zf_log[zf_Log] library for logging.

== Usage

[example]
----
 ./sna_bc   [-i|--input file] [-r|--nrun] [-b|--dump-scores file] 
            [-s|--dump-stats file] [-v|--verbose] [-c|--check]
            [-wsl|--wself-loops] [-d|--device] [-u|--usage] ][-h|--help]
----

== Hardware

The GPU used during the development of this project is a Quadro P620 with four Streaming Multiprocessors, a base clock of 2505 Mhz, two GB of GDDR5 memory and compute capability of 6.1 (Pascal architecture).

== Performance Analysis

- Speedup in regard to the reference parallel CPU algorithm of the PBGl.
- Throughput, in terms of TEPS.
- Runtime, measured in ms and related only to the GPU. This means that transfer times, either host to device and device to host, are ignored.
- Memory bandwidth for comparing thread blocks sizes.
- Vertex frontier evolution for comparing techniques.
- Impact of degree-1 reduction.

For gathering results the test is run multiple times, then the average runtime and std deviation is reported and the average MTEPS is computed from that average runtime.

To calculate TEPS, we require the number of edges traversed (touched), which we count dynamically. For traversal primitives, we note that non-connected components will not be visited, so the number of visited edges may be fewer than the number of edges in the graph.
