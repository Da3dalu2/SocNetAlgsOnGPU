= Implementazione di algoritmi paralleli su GPU per il calcolo d'indici di centralità nell'ambito dell'Analisi delle Reti Sociali
8 Aprile 2021
:toc-title: Tavola dei contenuti
:figure-caption: Fig.
:listing-caption: Listato
:section-refsig: Sezione
:version-label: ""
:stem: latexmath
:mathematical-format: svg
:xrefstyle: short
:source-highlighter: rouge
:rouge-style: bw
:source-linenums-option:
:source-indent: 2
:toc: macro
:sectnums:
:bibtex-file: ./docs/bibliography.bib
:bibtex-order: alphabetical
:bibtex-style: ieee
:bibtex-locale: it-IT
:srcdir: ../scripts
:imagesdir: ./images

:compiler_nvidia: nvcc 11.2.142
:compiler_local: GCC 10.2.1
:hardware_local: Intel Core i7-10700
:hardware_nvidia: Quadro P620
:BC: betweenness centrality

Università di Bologna · Campus di Cesena

Corso di Laurea Triennale in Ingegneria e Scienze Informatiche

'''

|=======
|Tirocinante |Riccardo Battistini, 0000873514
|Tutor didattico |Moreno Marzolla
|Laboratorio |High-Performance Computing
|Periodo di svolgimento del tirocinio |01/04/21 - 31/05/21
|=======

<<<

toc::[]

'''

== Introduzione

Il tirocinio è stato realizzato nell'ambito del laboratorio di High-Performance Computing per approfondire la programmazione di GPU e acquisire confidenza con il reperimento, la selezione e comprensione di testi di carattere scientifico, oltre che con alcuni concetti e algoritmi fondamentali nel campo dell'Analisi delle Reti Sociali e della Teoria dei Grafi.

== Tecnologie

Durante il tirocinio si è sviluppata un'applicazione a linea di
comando accelerata dalla GPU per il calcolo della _betweenness centrality_,
una metrica comunemente impiegata nel campo dell'Analisi delle Reti Sociali.

Per realizzare l'applicativo sono stati impiegati i linguaggi C, {cpp} e CUDA C.
In particolare il software realizzato impiega il Compute Unified Device Architecture (CUDA) Toolkit 11.2 cite:[cuda] e
gli standard C99 e {cpp}11. Come sistema per l'automazione dello sviluppo è stato impiegato il software multipiattaforma CMake 3.9. Git 2.3 è stato utilizzato per il controllo di versione.

Per la scrittura della documentazione del progetto sono stati impiegati
il linguaggio di markup Asciidoc, Gnuplot 5.2 per la creazione dei grafici e
Bibtex per la gestione della bibliografia.

Come formati per la memorizzazione dei dati sono stati impiegati Matrix Market,
standard per la rappresentazione di matrici sparse cite:[matrix-market],
e CSV per memorizzare i risultati della valutazione delle prestazioni e della scalabilità.

Infine per verificare il funzionamento dell'applicazione sono stati impiegati degli script in Bash 4.4.2, per la raccolta dei risultati, e Python 3.8, per processare i dati ottenuti.

L'applicazione è stata sviluppata e testata solo sul sistema operativo
Ubuntu 18.04. In ogni caso il funzionamento dovrebbe essere garantito senza problemi anche su altre distribuzioni GNU/Linux, MacOS e Windows, a patto che siano soddisfatte le link:https://github.com/Da3dalu2/SocNetAlgsOnGPU#references[dipendenze].

== Attività

=== Introduzione

Nel corso del tirocinio sono state approfondite alcune misure di centralità impiegate nel campo dell'analisi delle reti sociali.

In particolare sono stati consultati i primi studi relativi all'introduzione di questa metrica e quelli relativi a uno degli algoritmi sequenziali che per maggior tempo ha costituito lo stato dell'arte nel calcolo di questa metrica. La conoscenza acquisita e impiegata durante lo svolgimento del tirocinio è stata raccolta in <<Misure di centralità e betweenness>> e <<Algoritmo seriale di Brandes>>.

Successivamente si è proceduto con l'implementazione di un programma che fosse in grado di calcolare la {BC} prima in modo seriale e in seguito accelerando la computazione con una GPU. Il processo di sviluppo è dettagliato in <<Algoritmo parallelo su GPU>>.

Prima di procedere con l'implementazione è stato necessario riflettere sulla struttura dati principale da impiegare per la rappresentazione della rete e sulla scelta del formato di memorizzazione su disco. In <<Rappresentazione di un grafo>> si spiegano le decisioni prese.

Infine è stato effettuato uno studio delle prestazioni e della scalabilità dell'algoritmo implementato su insiemi di dati sintetici e reali. In particolare l'algoritmo su GPU è stato confrontato con l'algoritmo ottimizzato per architetture di tipo multi-core della libreria _Boost Graph Library_ (BGL) cite:[siek_boost_2002]. I risultati sono analizzati in <<Studio di scalabilità e throughput>>.

Come introduzione preliminare e a supporto degli argomenti trattati nel tirocinio sono state consultate diverse fonti cite:[cormen2009introduction, gkoulalas-divanis_large-scale_2014, Magnani2017].

Di seguito si assume che un grafo sia descritto come stem:[G = (V, E)], dove stem:[V] è l'insieme dei vertici ed stem:[E] l'insieme degli archi. Si impiegano stem:[n] ed stem:[m] rispettivamente per indicare il numero di vertici e di archi. Infine si considerano solo grafi connessi non diretti e non pesati.

=== Misure di centralità e betweenness

Le misure di centralità permettono di quantificare l'importanza di un nodo in base a diversi criteri, come la sua posizione nella rete, e costituiscono uno strumento fondamentale per l'analisi delle reti.

Una delle più note e diffuse misure di centralità è la _betweenness centrality_ cite:[freeman_set_1977, jm_anthonisse_rush_1971]. Si tratta di una misura della proporzione dei cammini minimi di una rete che attraversano uno specifico nodo.

In base alla classificazione proposta da Freeman cite:[freeman_set_1977, freeman_centrality_1978, freeman_gatekeeper_1980] si distinguono diversi tipi di misure di {BC} a seconda che la si stia considerando rispetto a un singolo vertice o all'intero grafo e che la misura sia normalizzata o meno.

Vertex {BC}:: La {BC} di un singolo vertice non normalizzata è definita come:

[latexmath, id="eq-bc", reftext={counter:refnum}]
++++
\begin{equation}
BC(v) \stackrel{\text { def }}{=} \sum_{s \neq v \neq t \in V} \frac{\sigma_{st}(v)}{\sigma_{st}}
\end{equation}
++++

Dove stem:[\sigma_{st}(v)] indica il numero di cammini minimi che passano da stem:[s] a stem:[t] e attraversano stem:[v] e stem:[\sigma_{st}] indica il numero di cammini minimi che passano per ogni coppia stem:[s, t \in V].

Normalized Vertex {BC}:: La {BC} di un singolo vertice normalizzata può essere riscritta a partire da (<<eq-bc>>) in questo modo:

[latexmath, id="eq-bc-norm"]
++++
BC \! ' \! (G) \stackrel{\text { def }}{=} \frac{BC(v)}{\max{ \ BC(v)}} = \frac{2 BC(v)}{(n - 1)(n - 2)} \quad 0 \le BC \! ' \! (v) \le 1
++++

Whole-network {BC}:: La {BC} come misura di tipo _whole-network_, ovvero riferita all'intera rete, è definita come la somma delle {BC} dei singoli vertici:

[latexmath, id="eq-bc-whole", reftext={counter:refnum}]
++++
\begin{equation}
BC(G) \stackrel{\text { def }}{=} \frac{\sum_{i = 1}^n \left[BC(v^*) - BC(v_i) \right]}{\max{\sum_{i = 1}^n \left[ BC(v^*) - BC(v_i) \right]}} = \frac{2 \sum_{i = 1}^n \left[BC(v^*) - BC(v_i) \right]}{(n - 1)^2(n - 2)}
\end{equation}
++++

Normalized Whole-network {BC}:: La {BC} di un grafo normalizzata può essere riscritta a partire da (<<eq-bc-whole>>) nel seguente modo:

[latexmath, id="eq-bc-whole-norm"]
++++
BC(G) \stackrel{\text { def }}{=} \frac{\sum_{i = 1}^n \left[BC\! ' \!(v^*) - BC\! ' \!(v_i) \right]}{(n - 1)}
++++

La {BC} si presta a diverse interpretazioni. Può esprimere la capacità di un nodo di controllare, distorcere, inibire o bloccare il flusso d'informazioni in una rete oppure può indicare quanto un nodo possa unire due o più gruppi di nodi e favorire lo scambio d'informazioni.

La {BC} è di particolare interesse anche perché è alla base di algoritmi più complessi come la _Community Detection_ e il suo calcolo efficiente in parallelo non è facile da realizzare.

=== Algoritmo seriale di Brandes

I primi algoritmi introdotti per il calcolo della {BC} sono piuttosto onerosi, cite:[freeman_set_1977, jm_anthonisse_rush_1971] eseguono in tempo stem:[\theta(n^3)] e richiedono stem:[\theta(n^2)] in termini di spazio. Impiegano l'algoritmo di Floyd-Warshall per risolvere il problema dell'APSP.

L'algoritmo sequenziale introdotto da Brandes cite:[brandes_faster_2001], rappresenta un notevole miglioramento rispetto ai precedenti in quanto esegue in tempo stem:[\theta(nm)] in grafi non pesati e richiede una minore occupazione di memoria. La {BC} (<<eq-bc>>) è calcolata come somma delle _pair dependency_ stem:[\delta_{s t}(v) = \sigma_{st}(v) / \sigma_{st}] di _s_ su _t_:

[latexmath, id="sum-pair-dep"]
++++
BC(v) \stackrel{\text { def }}{=} \sum_{s \neq v \neq t \in V} \delta_{s t}(v)
++++

Dove stem:[\delta_{st} (v)] indica la dipendenza di _s_ su _v_.

'''

Si definisce stem:[P_s(v)] l'insieme dei predecessori del vertice _v_ sui cammini minimi da _s_ come:

[latexmath, id="eq-prec"]
++++
P_s(v) = \{ u \in V: \{u,v\} \in E, d_G(s,v) = d_G(s,u) + \omega(u,v) \}
++++

Dove:

- stem:[d_G(s,v)] è la distanza tra i vertici stem:[s] e stem:[t], ovvero il cammino di lunghezza minore che congiunge i vertici stem:[s] e stem:[t] in stem:[G];
- stem:[d_G(s,v)] è la distanza tra i vertici stem:[s] e stem:[t], ovvero il cammino di lunghezza minore che congiunge i vertici stem:[s] e stem:[t] in stem:[G];
- stem:[\omega(u,v)] è una funzione peso definita sugli archi. In grafi non pesati si pone stem:[\omega(e) = 1, e \in E].

'''

Brandes dimostra che le dipendenze soddisfano la seguente relazione ricorsiva:

[latexmath, id="eq-rec"]
++++
\delta_{s \! *}(v) = \sum_{w, \! v \in P_{\! s}(w)} \frac{\sigma_{sv}}{\sigma_{sw}} \cdot \left(1 + \delta_{s \! *}(w) \right)
++++

Con questa relazione è possibile effettuare l'accumulazione delle dipendenze, riducendo sia l'occupazione in termini di memoria che il tempo richiesto. Ciò si verifica perché non è più necessario sommare esplicitamente le pair dependency.

L'algoritmo di Brandes impiega una tecnica di accumulazione che si integra con la risoluzione del problema dei cammini minimi tramite algoritmi di attraversamento dei grafi e permette di ottenere un notevole speedup. In particolare l'algoritmo di Brandes parte effettuando una BFS a partire da un vertice stem:[s]. La BFS individua un _Directed Acyclic Graph_ (DAG), radicato in stem:[s], e applicando la relazione ricorsiva <<eq-rec>> calcola la {BC} effettuando un'accumulazione che parte dalle foglie fino ad arrivare alla radice del DAG.

Nell'algoritmo di Brandes per il calcolo dei cammini minimi in un grafo non pesato si impiega una visita in ampiezza (BFS). Il tempo richiesto dalla BFS è pari a _θ(m)_. Di conseguenza il tempo richiesto per il calcolo di _δₛₜ, s, t ∈ V_ è pari a _θ(nm)_.

Applicando il risultato di Brandes, si ha che tutte le misure di centralità che richiedono il calcolo dei cammini minimi possono essere computate simultaneamente. Esempi di misure di questo tipo sono la _closeness centrality_ cite:[sabidussi_centrality_1966] e la varianti della {BC} cite:[brandes_variants_2008], come la _load centrality_ e la _stress centrality_.

== Algoritmo seriale SPVB

L'algoritmo SPVB, illustrato in <<alg-spvb>>, permette di sfruttare la struttura delle reti sociali per velocizzare significativamente l'algoritmo seriale di Brandes.

LA SPVB effettua il calcolo della {BC} dei vertici che appartengono agli alberi nella rete ottenuti eliminando iterativamente i nodi di grado unitario. L'idea che sta alla base dell'algoritmo è di eliminare i nodi che hanno un solo vicino in quanto possono essere unicamente il punto di arrivo di un cammino minimo ed hanno perciò {BC} nulla. Per poter eliminare questi nodi è prima necessario considerare l'impatto che hanno sulla {BC} del proprio vicino. Infatti ciascun vicino funge da collegamento per tutti gli altri nodi della rete poiché tutti i cammini minimi che partono da ciascun nodo di grado unitario passano per il rispettivo vicino.

La procedura SPVB ha quindi lo scopo di calcolare la {BC} di un vertice stem:[v] come la somma dei contributi di tutti i nodi stem:[u] che hanno stem:[v] come unico vicino. Successivamente è possibile eliminare i vertici di grado unitario dal grafo e gli archi stem:[(u,v)]. Se la rimozione di questo insieme di vertici genera altri vertici di grado unitario si può applicare nuovamente la procedura SPVB a patto di registrare il numero di nodi connessi a ciascuno dei nodi di grado unitario che sono stati rimossi dal grafo. In questo modo è possibile calcolare la {BC} di alberi del grafo.

Dal punto di vista formale l'insieme dei nodi di grado unitario stem:[F] che possono essere rimossi dal grafo stem:[G] è definito come stem:[F = \{ v \in V \ | \ deg(v) = 1 \} ]. I vertici in stem:[F] sono detti _tree-nodes_.

Il calcolo della {BC} di un vertice stem:[v \in V] richiede la somma di coppie di vertici stem:[s, t \in V]. Queste somme possono essere divise in più sotto-somme che coinvolgono o meno tree-nodes e possono essere calcolate con diversi algoritmi.

<<<

[source, pseudocode, id="alg-spvb"]
.Pseudocodice della Shortest Path Vertex Betweenneess
----
procedure SPVB(G)
let G.V be the set of vertices of the graph G
let G.n be the number of vertices in G
let v.d be the degree of a vertex v
let v.bc be the betweneess centrality of a vertex v
let p[] be an array # <1>
for v in G.V do # <2>
    label v.bc as 0
    label p[v] as 0
end
let i be the counter of the iterations done
let G_i be the i-th graph
let deg be a queue
label i as 0
label G_i as G
for v in G.V do # <3>
    if v.d = 1 then
        deg.enqueue(v)
    end
end
do
    deg.dequeue(v)
    let u be the set obtained from G_i.adjacentVertices(v)
    label u.bc as u.bc + 2(G.n - v.p - u.p - 2)(v.p + 1)
    label p[u] as p[u] + p[v] + 1
    label i as i + 1
    delete v from G_i
    label G_i.V as G_(i-1).V \ {v}
    label G_i.E as G_(i-1).E \ {(v,u)}
    if u.d = 1 then
        deg.enqueue(u)
    end
while deg is not empty
if G_i.n > 1 then
    BC_Mod_Computation(G_i)
end
----

<1> Per un vertice di grado unitario il vettore `p` indica il numero di vertici del sotto-albero radicato in `v` (esclusa la radice). Per un qualsiasi altro vertice `u`, `p` registra la somma delle dimensioni dei sotto-alberi radicati nei figli di quel vertice che non stati eliminati nelle precedenti iterazioni;
<2> Inizializzazione della {BC} di ogni vertice;
<3> Inizializzazione dell'insieme di nodi di grado unitario in `G`;

<<<

L'algoritmo SPVB, illustrato in <<alg-spvb>>, può essere eseguito su grafi disconnessi applicandolo a ogni componente connessa separatamente.

<<<

[source, pseudocode, id="alg-brandes-mod"]
.Algoritmo modificato per il calcolo della betweenness centrality di Brandes
----
procedure BC_Mod_Computation(G)
let G.V be the set of vertices of the graph G
let v.bc be the betweneess centrality of a vertex v
let v.p be the number of tree nodes connected to a vertex v
for v in G.V do # <1>
    label v.bc as 0
end
for v in G.V do
    for s in G.V do
        let v.d be the distance of a vertex v from s
        let v.δ be the pair dependency of a vertex v on s
        let v.σ be the shortest path from v to s
        label v.d as -1
        label v.δ as 0
        label v.σ as 0
    end
    let S be a stack
    let Q be a queue
    let P be a list
    label v.σ as 1
    label v.d as 0
    Q.enqueue(s)
    while Q is not empty do
        Q.dequeue(v)
        S.push(v)
        for w in G.adjacentVertices(v) do # <2>
            if w.d < 0 then # <3>
                Q.enqueue(w)
                label w.d as v.d + 1
            end
            if w.d = v.d + 1 then # <4>
                label w.σ as w.σ + v.σ
                P.append(v)
            end
        end
    end
    while S is not empty do # <5>
        S.pop(w)
        for v in P do
            label v.δ as
                v.δ + (v.σ / w.σ) * (1 + w.δ + w.p)
        end
        if w != s then
            label w.bc as w.bc + w.δ * (1 + s.p)
        end
    end
----

<<<

<1> Inizializzazione della {BC} di ogni vertice;
<2> Esamina i vicini di `v`;
<3> Se `w` non è stato ancora scoperto;
<4> Se è un cammino minimo verso `w` che attraversa `v`;
<5> Lo stack `S` restituisce i vertici in ordine non crescente di distanza da `s`.

=== Rappresentazione di un grafo

Un grafo generalmente è rappresentato in due modi: come collezione di liste di adiacenza e come una matrice di adiacenza.

Entrambe i metodi permettono di rappresentare grafi sparsi, ovvero in cui stem:[|E| \ll |V|^2], impiegando opportuni formati di memorizzazione approfonditi in seguito. Tuttavia le operazioni di ricerca nella collezione di liste di adiacenza hanno costo lineare rispetto al numero di vertici mentre in una rappresentazione come matrice di adiacenza il costo è costante.

Dato che per il calcolo delle misure di centralità d'interesse si impiegano degli algoritmi che non richiedono l'inserimento o la rimozione di vertici dai grafi in analisi e che sono necessarie frequenti operazioni di ricerca per determinare se c'è un arco che collega due vertici, si preferisce l'uso della rappresentazione come matrice di adiacenza.

Dato un grafo stem:[G], con stem:[n] vertici si ha che nella matrice di adiacenza stem:[A(G) \ n \times n]:

- stem:[A_{ij} = 1] se esiste un arco che congiunge il vertice stem:[i] al vertice stem:[j];
- stem:[A_{ij} = 0] altrimenti.

Si osserva che la matrice di adiacenza di un grafo non diretto ha due elementi per ogni arco, ovvero stem:[(1,2)] è rappresentato come stem:[A_{12} = 1] e stem:[A_{21} = 1]. Ciò significa che la matrice di adiacenza di un grafo non diretto è simmetrica, ovvero stem:[A_{ij} = A_{ji}]. Questa proprietà può essere sfruttata, come accade nel formato Matrix Market, per ridurre significativamente l'occupazione su disco di questa tipologia di grafi.

Un altro vantaggio dovuto alla scelta della matrice di adiacenza sta nel poter definire con chiarezza gli schemi di accesso ai dati e di realizzare una rappresentazione più efficiente per la cache. In questo modo è possibile parallelizzare efficacemente e con maggior facilità gli algoritmi su grafi. In particolare una matrice di adiacenza, come si può vedere nel <<matrix>>, può essere rappresentata in un formato che sfrutta il principio di località tramite l'impiego di una _Structure of Arrays_ (SoA).

[source, c, id="matrix"]
.Matrice di adiacenza rappresentata come SoA in C
----
typedef struct {
    int nrows # <1>
    int *rows; # <2>
    int *cols; # <3>
    int *values; # <4>
} matrix_t;
----

<1> Numero di vertici stem:[n];
<2> indice riga per ogni elemento;
<3> indice colonna per ogni elemento:
<4> valore di ogni elemento. È omesso se si vuole rappresentare un grafo con pesi uniformi.

Dato che i grafi che si incontrano nell'ambito dell'analisi delle reti sociali sono sparsi {wj}citenp:[barabasi2016network(13)], ovvero stem:[|E| \ll |V|^2], e di notevoli dimensioni (da centinaia di migliaia a milioni di vertici e in crescita) il costo stem:[\theta(n^2)] della tipologia di rappresentazione scelta in termini di occupazione di memoria non è sostenibile. Perciò si sfruttano le caratteristiche strutturali di queste reti rappresentandole come matrici sparse, ovvero come matrici in cui gli elementi nulli sono omessi. In questo modo è possibile ottenere un notevole risparmio in termini di occupazione di memoria in funzione del grado di sparsità della rete. Un esempio di matrice sparsa si ha in <<sparse-matrix>>.

[[sparse-matrix]]
.Rappresentazione di una matrice sparsa simmetrica ottenuta dal dataset `ca-GrQc`, costruito a partire dalla rete di collaborazioni delle pubblicazioni nel campo della Relatività Generale e della Cosmologia Quantica su arXiv dal 1993 al 2003. Il grafico è stato realizzato tramite la funzione `spy` in GNU Octave. Il grado di sparsità della matrice è superiore al 95%.
image::../fig1.png[Esempio di matrice sparsa, align="center", pdfwidth="70%"]

Esistono diversi metodi per rappresentare una matrice sparsa, ciascuno avente impatto sia sull'occupazione del disco che sulle prestazioni del programma a tempo di esecuzione. Alcuni dei formati di memorizzazione più noti sono _COOrdinate Format_ (COO) e _Compressed Sparse Row_ (CSR).

A partire dal <<matrix>> si può ottenere la rappresentazione di una matrice di adiacenza in formato COO:

[source, c, id="coo"]
.Matrice di adiacenza rappresentata in formato COO in C
----
typedef struct {
    int nrows;
    int nnz; # <1>
    int *rows; # <2>
    int *cols; # <3>
    int *values; # <4>
} matrix_coo_t;
----

<1> Numero di elementi non nulli, ovvero _number of non-zeros_;
<2> indice riga per ogni elemento non nullo;
<3> indice colonna per ogni elemento non nullo;
<4> valore di ogni elemento non nullo.

Il formato COO rappresenta il modo più semplice per memorizzare una matrice sparsa ma non è particolarmente efficiente. Ad esempio, in un grafo diretto con stem:[n] vertici se si effettua una ricerca per stabilire se il vertice ennesimo è legato a un altro è necessario scorrere tutti gli stem:[n] elementi del vettore `rows` prima di poter ottenere il risultato. Ciò accade perché nel vettore `rows` sono memorizzati tutti i valori ripetuti degli indici riga degli elementi non nulli. Il formato CSR è stato introdotto per eliminare gli elementi ridondanti in `rows` e per rendere la ricerca di un elemento più rapida. Questo formato è molto simile alla rappresentazione di un grafo tramite liste di adiacenza ma non ha i costi aggiuntivi legati all'uso dei puntatori ed è molto più efficiente nell'uso della cache.

[source, c, id="csr"]
.Matrice di adiacenza rappresentata in formato CSR in C
----
typedef struct {
    int nrows;
    int *row_offsets; # <1>
    int *cols; # <2>
    int *values;
} matrix_csr_t;
----

<1> Punta all'inizio e alla fine di ciascun lista di adiacenza contenuta in `cols` ed è formato da `nrows+1` elementi. L'ultimo valore memorizza il numero totale di elementi non nulli perciò non è necessario memorizzare il campo `nnz`;
<2> rappresenta la concatenazione delle liste di adiacenza di ciascun vertice in un vettore di `nrows` elementi.

Perché sia possibile stabilire se conviene rappresentare una matrice stem:[M] in uno di questi formati è necessario determinare il suo grado di sparsità stem:[S]. Quest'ultimo può essere definito in percentuale nel seguente modo:

[latexmath, id="eq-sparsity"]
++++
S(M) \stackrel{\text { def }}{=} \left(1 - \frac{nnz}{n^2} \right) \cdot 100
++++

Sapendo che il costo in termini di memoria per la rappresentazione di stem:[M] è pari a stem:[\theta(3 nnz)] in formato COO e a stem:[\theta(2 nnz + n)] in formato CSR si ha che perché sia conveniente rappresentare stem:[M] in formato COO deve valere:

[latexmath, id="eq-coo"]
++++
nnz \ < \ \frac{n^2}{3}
++++

per il formato CSR deve valere:

[latexmath, id="eq-csr"]
++++
nnz \ < \ \frac{n (n - 1)}{2}
++++

I dataset impiegati per valutare l'algoritmo parallelo implementato in <<Studio di scalabilità e throughput>> sono stati memorizzati su disco con il formato COO e in memoria principale con il formato CSR. La scelta è motivata dal grado di sparsità superiore al 90% in tutte le reti considerate.

=== Algoritmo parallelo su GPU

cite:[jia_chapter_2012]

=== Studio di scalabilità e throughput

Per i test sono stati impiegati una CPU {hardware_local} con frequenza di funzionamento pari a 2.9 Ghz, una cache di 16 Mb e 16 Gb di DRAM.

La GPU è una {hardware_nvidia} con quattro _Streaming Multiprocessors_ e clock di base di 2505 Mhz. La memoria GDDR5 a disposizione è pari a due Gb e la _compute capability_ è 6.1 (architettura Pascal).

I dataset per effettuare i test sono reperibili nella _Sparse Matrix Collection_ dell'Università della Florida cite:[davis_university_2011] e dalla _Standford Network Analysis Platform_ (SNAP) cite:[snapnets].

Per la generazione casuale di grafi secondo i modelli di Erdös-Rényi, Watts-Strogatz e Barabàsi-Albert citenp:[gkoulalas-divanis_large-scale_2014(7)] sono state impiegate le funzioni rese disponibili dalla libreria SNAP cite:[leskovec2016snap].

Di seguito si analizzano i risultati ottenuti.

== Conclusioni

In questa parte lo studente trae le conclusioni del lavoro svolto, valutando
pregi e difetti dell’esperienza e, più specificamente, riassumendo quanto
appreso.

Il software sviluppato è liberamente disponibile in un link:https://github.com/Da3dalu2/SocNetAlgsOnGPU[repository su GitHub].

Impiegando l'algoritmo di DIjstra nel caso di pesi positivi o di Bellman Ford nel caso di pesi negativi è possibile applicare ...

<<<

[bibliography]
== Riferimenti bibliografici

bibliography::[]
